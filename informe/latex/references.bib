@article{IntroductionTDA,
    title    = "An Introduction to Topological Data Analysis: Fundamental and
                Practical Aspects for Data Scientists",
    author   = "Chazal, Fr{\'e}d{\'e}ric and Michel, Bertrand",
    abstract = "With the recent explosion in the amount, the variety, and the
                dimensionality of available data, identifying, extracting, and
                exploiting their underlying structure has become a problem of
                fundamental importance for data analysis and statistical
                learning. Topological data analysis (tda) is a recent and
                fast-growing field providing a set of new topological and
                geometric tools to infer relevant features for possibly complex
                data. It proposes new well-founded mathematical theories and
                computational tools that can be used independently or in
                combination with other data analysis and statistical learning
                techniques. This article is a brief introduction, through a few
                selected topics, to basic fundamental and practical aspects of
                tda for nonexperts.",
    journal  = "Front Artif Intell",
    volume   =  4,
    pages    = "667963",
    month    =  sep,
    year     =  2021,
    keywords = "geometric inference; machine learning; statistic; topological
                data analysis; topological inference",
    language = "en"
}

@book{IntroductionComputationalTopology,
  added-at = {2020-01-09T11:56:48.000+0100},
  author = {Edelsbrunner, Herbert and Harer, John},
  biburl = {https://www.bibsonomy.org/bibtex/26dda9959e979657f0d5064d9128f91de/annakrause},
  ee = {http://www.ams.org/bookstore-getitem/item=MBK-69},
  interhash = {d2c05748c9293370770bcfeb95573a87},
  intrahash = {6dda9959e979657f0d5064d9128f91de},
  isbn = {978-0-8218-4925-5},
  keywords = {algebraictopology},
  pages = {I-XII, 1-241},
  publisher = {American Mathematical Society},
  timestamp = {2020-01-09T11:56:48.000+0100},
  title = {Computational Topology - an Introduction.},
  year = 2010
}

@article{ConfidenceSetsForPersistenceDiagrams,
    author = {Brittany Terese Fasy and Fabrizio Lecci and Alessandro Rinaldo and Larry Wasserman and Sivaraman Balakrishnan and Aarti Singh},
    title = {{Confidence sets for persistence diagrams}},
    volume = {42},
    journal = {The Annals of Statistics},
    number = {6},
    publisher = {Institute of Mathematical Statistics},
    pages = {2301 -- 2339},
    keywords = {Density estimation, Persistent homology, topology},
    year = {2014},
    doi = {10.1214/14-AOS1252},
    URL = {https://doi.org/10.1214/14-AOS1252}
}

@article{CubicalPersistentDiagrams,
  TITLE = {{Rigorous cubical approximation and persistent homology of continuous functions}},
  AUTHOR = {Dlotko, Pawel and Wanner, Thomas},
  URL = {https://hal.science/hal-01706695},
  JOURNAL = {{Computers \& Mathematics with Applications}},
  PUBLISHER = {{Elsevier}},
  YEAR = {2018},
  MONTH = Mar,
  PDF = {https://hal.science/hal-01706695/file/rigorousPersistence.pdf},
  HAL_ID = {hal-01706695},
  HAL_VERSION = {v1},
}

@article{TDAUsingPersistenceLandscapes,
    doi = {10.48550/ARXIV.1207.6437},
    url = {https://arxiv.org/abs/1207.6437},
    author = {Bubenik, Peter},
    keywords = {Algebraic Topology (math.AT), Computational Geometry (cs.CG), Metric Geometry (math.MG), Statistics Theory (math.ST), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences, 55N99, 68W30, 62G99, 54E35},
    title = {Statistical topological data analysis using persistence landscapes},
    publisher = {arXiv},
    year = {2012},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{StochasticConvergencePersistenceLandscapes,
    author = {Chazal, Fr\'{e}d\'{e}ric and Fasy, Brittany Terese and Lecci, Fabrizio and Rinaldo, Alessandro and Wasserman, Larry},
    title = {Stochastic Convergence of Persistence Landscapes and Silhouettes},
    year = {2014},
    isbn = {9781450325943},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2582112.2582128},
    doi = {10.1145/2582112.2582128},
    abstract = {Persistent homology is a widely used tool in Topological Data Analysis that encodes multiscale topological information as a multi-set of points in the plane called a persistence diagram. It is difficult to apply statistical theory directly to a random sample of diagrams. Instead, we can summarize the persistent homology with the persistence landscape, introduced by Bubenik, which converts a diagram into a well-behaved real-valued function. We investigate the statistical properties of landscapes, such as weak convergence of the average landscapes and convergence of the bootstrap. In addition, we introduce an alternate functional summary of persistent homology, which we call the silhouette, and derive an analogous statistical theory.},
    booktitle = {Proceedings of the Thirtieth Annual Symposium on Computational Geometry},
    pages = {474–483},
    numpages = {10},
    keywords = {persistent homology, bootstrap, empirical processes},
    location = {Kyoto, Japan},
    series = {SOCG'14}
}

@misc{WikipediaHomology,
    author = "Wikipedia",
    title = "{Homology (mathematics)} --- {W}ikipedia{,} The Free Encyclopedia",
    year = "2022",
    howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Homology\%20(mathematics)&oldid=1098660019}},
    note = "[Online; accessed 22-August-2022]"
 }

@article{AllStatsPersistenceHomology,
  author = {Blumberg, Andrew J. and Gal, Itamar and Mandell, Michael A. and Pancia, Matthew},
  title = {Robust Statistics, Hypothesis Testing, and Confidence Intervals for Persistent Homology on Metric Measure Spaces},
  year = {2014},
  issue_date = {August 2014},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  volume = {14},
  number = {4},
  issn = {1615-3375},
  url = {https://doi.org/10.1007/s10208-014-9201-4},
  doi = {10.1007/s10208-014-9201-4},
  abstract = {We study distributions of persistent homology barcodes associated to taking subsamples of a fixed size from metric measure spaces. We show that such distributions provide robust invariants of metric measure spaces and illustrate their use in hypothesis testing and providing confidence intervals for topological data analysis.},
  journal = {Found. Comput. Math.},
  month = {aug},
  pages = {745–789},
  numpages = {45},
  keywords = {55U10, 68U05, Barcode space, Bottleneck metric, Confidence interval, Gromov---Prohorov metric, Hypothesis testing, Metric measure space, Persistent homology, Robustness, Stability}
}

@INPROCEEDINGS{RobustHausdorffDistance,
  author={Dang-Nguyen, Chau and Do-Hong, Tuan},
  booktitle={2019 International Symposium on Electrical and Electronics Engineering (ISEE)},
  title={Robust Line Hausdorff Distance for Face Recognition},
  year={2019},
  volume={},
  number={},
  pages={103-107},
  keywords={Image edge detection;Face;Face recognition;Databases;Lighting;Robustness;Training;Edge map;LHD;Hausdorff distance;Robust LHD},
  doi={10.1109/ISEE2.2019.8921218}
}

@article{StatisticalApproachToPersistentHomology,
    author = {Peter Bubenik and Peter T. Kim},
    title = {{A statistical approach to persistent homology}},
    volume = {9},
    journal = {Homology, Homotopy and Applications},
    number = {2},
    publisher = {International Press of Boston},
    pages = {337 -- 362},
    keywords = {directional statistics, expected persistent homology, parametric statistics, Persistent homology, point cloud data},
    year = {2007},
    doi = {hha/1201127341},
    URL = {https://doi.org/}
}

@book{GudhiDoc,
    title        = "{GUDHI} User and Reference Manual",
    author      = "{The GUDHI Project}",
    publisher     = "{GUDHI Editorial Board}",
    year         = 2015,
    url =    "http://gudhi.gforge.inria.fr/doc/latest/",
}

@misc{GiottoDoc,
    doi = {10.48550/ARXIV.2107.05412},
    url = {https://arxiv.org/abs/2107.05412},
    author = {Pérez, Julián Burella and Hauke, Sydney and Lupo, Umberto and Caorsi, Matteo and Dassatti, Alberto},
    keywords = {Computational Geometry (cs.CG), Mathematical Software (cs.MS), FOS: Computer and information sciences, FOS: Computer and information sciences, G.4; G.2.2, 68R99},
    title = {giotto-ph: A Python Library for High-Performance Computation of Persistent Homology of Vietoris-Rips Filtrations},
    publisher = {arXiv},
    year = {2021},
    copyright = {Creative Commons Attribution 4.0 International}
}

@article{FormationOfGiantKCycles,
  author = {Bobrowski, Omer and Skraba, Primoz},
  title = "{Homological Percolation: The Formation of Giant k-Cycles}",
  journal = {International Mathematics Research Notices},
  volume = {2022},
  number = {8},
  pages = {6186-6213},
  year = {2020},
  month = {12},
  abstract = "{In this paper we introduce and study a higher dimensional analogue of the giant component in continuum percolation. Using the language of algebraic topology, we define the notion of giant \$k\$-dimensional cycles (with \$0\$-cycles being connected components). Considering a continuum percolation model in the flat \$d\$-dimensional torus, we show that all the giant \$k\$-cycles (\$1\\le k \\le d-1\$) appear in the regime known as the thermodynamic limit. We also prove that the thresholds for the emergence of the giant \$k\$-cycles are increasing in \$k\$ and are tightly related to the critical values in continuum percolation. Finally, we provide bounds for the exponential decay of the probabilities of giant cycles appearing.}",
  issn = {1073-7928},
  doi = {10.1093/imrn/rnaa305},
  url = {https://doi.org/10.1093/imrn/rnaa305},
  eprint = {https://academic.oup.com/imrn/article-pdf/2022/8/6186/43396064/rnaa305.pdf},
}

@article{TDAMedicineStudies,
  title={Topological Data Analysis and its usefulness for precision medicine studies},
  volume={46},
  url={https://raco.cat/index.php/SORT/article/view/401140},
  DOI={10.2436/20.8080.02.120},
  number={1},
  journal={SORT-Statistics and Operations Research Transactions},
  author={Iniesta, Raquel and Ewan, Carr and Mathieu, Carrière and Naya, Yerolemou and Bertrand, Michel and Frédéric, Chazal},
  year={2022},
  month={Jun.},
  pages={115-136}
}

@article{IntrinsicPersistentHomologyFermatDistance,
  author = {Fern\'{a}ndez, Ximena and Borghini, Eugenio and Mindlin, Gabriel and Groisman, Pablo},
  title = {Intrinsic persistent homology via density-based metric learning},
  year = {2024},
  issue_date = {January 2023},
  publisher = {JMLR.org},
  volume = {24},
  number = {1},
  issn = {1532-4435},
  abstract = {We address the problem of estimating topological features from data in high dimensional Euclidean spaces under the manifold assumption. Our approach is based on the computation of persistent homology of the space of data points endowed with a sample metric known as Fermat distance. We prove that such metric space converges almost surely to the manifold itself endowed with an intrinsic metric that accounts for both the geometry of the manifold and the density that produces the sample. This fact implies the convergence of the associated persistence diagrams. The use of this intrinsic distance when computing persistent homology presents advantageous properties such as robustness to the presence of outliers in the input data and less sensitiveness to the particular embedding of the underlying manifold in the ambient space. We use these ideas to propose and implement a method for pattern recognition and anomaly detection in time series, which is evaluated in applications to real data.},
  journal = {J. Mach. Learn. Res.},
  month = {mar},
  articleno = {75},
  numpages = {42},
  keywords = {topological data analysis, persistent homology, manifold learning, distance learning, time series}
}


@article{CoverageSensorNetworksPersistentHomology,
    author = {Vin de Silva and Robert Ghrist},
    title = {{Coverage in sensor networks via persistent homology}},
    volume = {7},
    journal = {Algebraic & Geometric Topology},
    number = {1},
    publisher = {MSP},
    pages = {339 -- 358},
    keywords = {Cech complex, coverage, Persistent homology, Rips complex, sensor network},
    year = {2007},
    doi = {10.2140/agt.2007.7.339},
    URL = {https://doi.org/10.2140/agt.2007.7.339}
}

@article{DelayEmbeddingsWheezeDetectionPersistentHomology,
  author={Emrani, Saba and Gentimis, Thanos and Krim, Hamid},
  journal={IEEE Signal Processing Letters},
  title={Persistent Homology of Delay Embeddings and its Application to Wheeze Detection},
  year={2014},
  volume={21},
  number={4},
  pages={459-463},
  doi={10.1109/LSP.2014.2305700}
}

@article{DynamicalSystemsFeaturePersistentHomology,
	doi = {10.1063/1.4949472},
	url = {https://doi.org/10.1063%2F1.4949472},
	year = 2016,
	month = {may},
	publisher = {{AIP} Publishing},
	volume = {26},
	number = {5},
	pages = {053105},
	author = {Slobodan Maleti{\'{c}} and Yi Zhao and Milan Rajkovi{\'{c}}},
	title = {Persistent topological features of dynamical systems},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}
}

@article{TopologicalTimeSeriesPersistentHomology,
  title={Topological Time Series Analysis},
  author={Jose A. Perea},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.05143},
  url={https://api.semanticscholar.org/CorpusID:56148259}
}

@article{RepresentationLearningBengio,
  author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  title = {Representation Learning: A Review and New Perspectives},
  year = {2013},
  issue_date = {August 2013},
  publisher = {IEEE Computer Society},
  address = {USA},
  volume = {35},
  number = {8},
  issn = {0162-8828},
  url = {https://doi.org/10.1109/TPAMI.2013.50},
  doi = {10.1109/TPAMI.2013.50},
  abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  month = {aug},
  pages = {1798–1828},
  numpages = {31},
  keywords = {unsupervised learning, representation learning, neural nets, feature learning, autoencoder, Speech recognition, Neural networks, Manifolds, Machine learning, Learning systems, Feature extraction, Deep learning, Boltzmann machine, Abstracts}
}

@Article{Niyogi2008,
    author={Niyogi, Partha
    and Smale, Stephen
    and Weinberger, Shmuel},
    title={Finding the Homology of Submanifolds with High Confidence from Random Samples},
    journal={Discrete {\&} Computational Geometry},
    year={2008},
    month={Mar},
    day={01},
    volume={39},
    number={1},
    pages={419-441},
    abstract={Recently there has been a lot of interest in geometrically motivated approaches to data analysis in high-dimensional spaces. We consider the case where data are drawn from sampling a probability distribution that has support on or near a submanifold of Euclidean space. We show how to ``learn'' the homology of the submanifold with high confidence. We discuss an algorithm to do this and provide learning-theoretic complexity bounds. Our bounds are obtained in terms of a condition number that limits the curvature and nearness to self-intersection of the submanifold. We are also able to treat the situation where the data are ``noisy'' and lie near rather than on the submanifold in question.},
    issn={1432-0444},
    doi={10.1007/s00454-008-9053-2},
    url={https://doi.org/10.1007/s00454-008-9053-2}
}

@article{NerveTheorem,
  title = {A unified view on the functorial nerve theorem and its variations},
  journal = {Expositiones Mathematicae},
  volume = {41},
  number = {4},
  pages = {125503},
  year = {2023},
  issn = {0723-0869},
  doi = {https://doi.org/10.1016/j.exmath.2023.04.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0723086923000415},
  author = {Ulrich Bauer and Michael Kerber and Fabian Roll and Alexander Rolle},
  keywords = {Nerve theorem, Applied topology, Delaunay complex, Čech complex, Model categories, Discrete Morse theory},
  abstract = {The nerve theorem is a basic result of algebraic topology that plays a central role in computational and applied aspects of the subject. In topological data analysis, one often needs a nerve theorem that is functorial in an appropriate sense, and furthermore one often needs a nerve theorem for closed covers as well as for open covers. While the techniques for proving such functorial nerve theorems have long been available, there is unfortunately no general-purpose, explicit treatment of this topic in the literature. We address this by proving a variety of functorial nerve theorems. First, we show how one can use elementary techniques to prove nerve theorems for covers by closed convex sets in Euclidean space, and for covers of a simplicial complex by subcomplexes. Then, we establish a more general, “unified” nerve theorem that subsumes many of the variants, using standard techniques from abstract homotopy theory.}
}

@article{FootballRobustDataset,
  author = {Chazal, Fr\'{e}d\'{e}ric and Fasy, Brittany and Lecci, Fabrizio and Michel, Bertrand and Rinaldo, Alessandro and Rinaldo, Alessandro and Wasserman, Larry},
  title = {Robust topological inference: distance to a measure and kernel distance},
  year = {2017},
  issue_date = {January 2017},
  publisher = {JMLR.org},
  volume = {18},
  number = {1},
  issn = {1532-4435},
  abstract = {Let P be a distribution with support S. The salient features of S can be quantified with persistent homology, which summarizes topological features of the sublevel sets of the distance function (the distance of any point x to S). Given a sample from P we can infer the persistent homology using an empirical version of the distance function. However, the empirical distance function is highly non-robust to noise and outliers. Even one outlier is deadly. The distance-to-a-measure (DTM), introduced by Chazal et al. (2011), and the kernel distance, introduced by Phillips et al. (2014), are smooth functions that provide useful topological information but are robust to noise and outliers. Chazal et al. (2015) derived concentration bounds for DTM. Building on these results, we derive limiting distributions and confidence sets, and we propose a method for choosing tuning parameters.},
  journal = {J. Mach. Learn. Res.},
  month = {jan},
  pages = {5845–5884},
  numpages = {40},
  keywords = {RKHS, persistent homology, topological data analysis}
}

@inproceedings{FootballRobustDatasetExplanation,
author = {Pettersen, Svein and Johansen, Dag and Dagenborg, Håvard and Berg-Johansen, Vegard and Gaddam, Vamsidhar and Mortensen, Asgeir and Langseth, Ragnar and Griwodz, Carsten and Stensland, Håkon and Halvorsen, Pål},
year = {2014},
month = {03},
pages = {},
title = {Soccer Video and Player Position Dataset},
journal = {Proceedings of the 5th ACM Multimedia Systems Conference, MMSys 2014},
doi = {10.1145/2557642.2563677}
}

@article{ParamethricInferencePersistenceDiagrams,
  author = {Bobrowski, Omer and Skraba, Primoz},
  year = {2023},
  month = {07},
  pages = {},
  title = {A universal null-distribution for topological data analysis},
  volume = {13},
  journal = {Scientific Reports},
  doi = {10.1038/s41598-023-37842-2}
}

% Estadistica basica

 @book{
    IntroductoryStats,
    place={Houston, TX},
    title={Introductory statistics},
    publisher={OpenStax, Rice University},
    author={Illowsky, Barbara and Dean, Susan L. and Illowsky, Barbara},
    year={2018}
}


@book{IntroBootstrap,
  title={An Introduction to the Bootstrap},
  author={Efron, B. and Tibshirani, R.J.},
  isbn={9780412042317},
  lccn={93004489},
  series={Chapman \& Hall/CRC Monographs on Statistics \& Applied Probability},
  url={https://books.google.com.br/books?id=gLlpIUxRntoC},
  year={1994},
  publisher={Taylor \& Francis}
}

@misc{WikiBootstrap,
   author = "Wikipedia",
   title = "{Bootstrapping (statistics)} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2024",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Bootstrapping\%20(statistics)&oldid=1244613103}},
   note = "[Online; accessed 13-September-2024]"
}


﻿@Article{SubsamplingAndHalf,
    author={Babu, Gutti Jogesh},
    title={Subsample and half-sample methods},
    journal={Annals of the Institute of Statistical Mathematics},
    year={1992},
    month={Dec},
    day={01},
    volume={44},
    number={4},
    pages={703-720},
    issn={1572-9052},
    doi={10.1007/BF00053399},
    url={https://doi.org/10.1007/BF00053399}
}

% Fin estadistica basica

% Inicio Fermat distance

@Article{PatuPercolationDistanceLearning,
  Author = {Groisman, Pablo and Jonckheere, Matthieu and Sapienza, Facundo},
  Title = {Nonhomogeneous {Euclidean} first-passage percolation and distance learning},
  FJournal = {Bernoulli},
  Journal = {Bernoulli},
  ISSN = {1350-7265},
  Volume = {28},
  Number = {1},
  Pages = {255--276},
  Year = {2022},
  Language = {English},
  DOI = {10.3150/21-BEJ1341},
  Keywords = {60K35,60G55,60D05,68P10,82D30},
  URL = {projecteuclid.org/journals/bernoulli/volume-28/issue-1/Nonhomogeneous-Euclidean-first-passage-percolation-and-distance-learning/10.3150/21-BEJ1341.full},
  zbMATH = {7467721},
  Zbl = {1491.60178}
}

@inproceedings{FermatLandmarks,
author = {Potamias, Michalis and Bonchi, Francesco and Castillo, Carlos and Gionis, Aristides},
title = {Fast shortest path distance estimation in large networks},
year = {2009},
isbn = {9781605585123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1645953.1646063},
doi = {10.1145/1645953.1646063},
abstract = {In this paper we study approximate landmark-based methods for point-to-point distance estimation in very large networks. These methods involve selecting a subset of nodes as landmarks and computing offline the distances from each node in the graph to those landmarks. At runtime, when the distance between a pair of nodes is needed, it can be estimated quickly by combining the precomputed distances. We prove that selecting the optimal set of landmarks is an NP-hard problem, and thus heuristic solutions need to be employed. We therefore explore theoretical insights to devise a variety of simple methods that scale well in very large networks. The efficiency of the suggested techniques is tested experimentally using five real-world graphs having millions of edges. While theoretical bounds support the claim that random landmarks work well in practice, our extensive experimentation shows that smart landmark selection can yield dramatically more accurate results: for a given target accuracy, our methods require as much as 250 times less space than selecting landmarks at random. In addition, we demonstrate that at a very small accuracy loss our techniques are several orders of magnitude faster than the state-of-the-art exact methods. Finally, we study an application of our methods to the task of social search in large graphs.},
booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge Management},
pages = {867–876},
numpages = {10},
keywords = {shortest-paths, landmarks methods, graphs},
location = {Hong Kong, China},
series = {CIKM '09}
}

@inproceedings{PatuFermatDistance,
  title={Weighted Geodesic Distance Following Fermat's Principle},
  author={Facundo Sapienza and Pablo Groisman and Matthieu Jonckheere},
  booktitle={International Conference on Learning Representations},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:34393656}
}

% Fin Fermat Distance


% Inicio de la sección de donde copie imagenes

@phdthesis{ImagenHausdorff,
  author = {Pellerin, Jeanne},
  year = {2014},
  month = {03},
  pages = {},
  title = {Accounting for the geometrical complexity of geological structural models in Voronoi-based meshing methods},
  doi = {10.13140/RG.2.1.2719.2169}
}


@INPROCEEDINGS{ImagenPersistenceDiagramLinda,
  author={Wong, Chi-Chong and Vong, Chi-Man},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  title={Persistent Homology based Graph Convolution Network for Fine-grained 3D Shape Segmentation},
  year={2021},
  volume={},
  number={},
  pages={7078-7087},
  keywords={Deep learning;Point cloud compression;Solid modeling;Three-dimensional displays;Convolution;Computational modeling;Semantics;Segmentation;grouping and shape},
  doi={10.1109/ICCV48922.2021.00701}
}

@inbook{ImagenRipsVsVietorisClara,
   title={Random Simplicial Complexes: Models and Phenomena},
   ISBN={9783030913748},
   ISSN={1860-0840},
   url={http://dx.doi.org/10.1007/978-3-030-91374-8_2},
   DOI={10.1007/978-3-030-91374-8_2},
   booktitle={Higher-Order Systems},
   publisher={Springer International Publishing},
   author={Bobrowski, Omer and Krioukov, Dmitri},
   year={2022},
   pages={59–96}
}
