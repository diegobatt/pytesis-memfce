A continuación se disponen los resultados obtenidos de las regiones de confianza para los conjuntos de datos introducidos en la @sec-methods-data-synth. Se observa en primera instancia un ejemplo de resultado de diagrama de persistencia junto con su región de confianza para cada método desarrollado en la @sec-methods-intervals y posteriormente se procede a repetir el experimento una cantidad $M$ de veces para analizar la potencia, estimada como la tasa de aciertos a la hora de rechazar la hipótesis nula $H_0$ dado que la misma es falsa para distintas muestras de una misma variedad subyacente. Dicho en otras palabras, decidir que hay cualidades topológicas de primer grado (agujeros) en el conjunto de datos, dado que efectivamente las hay. Este análisis se realiza para cada uno de los métodos utilizados sobre los distintos espacios topológicos sintéticos presentados, disponiendo los resultados en forma de tablas.

```{python}
import warnings
warnings.simplefilter(action="ignore", category=FutureWarning)
warnings.simplefilter(action="ignore", category=UserWarning)

from pytesis.datasets import (
    arc,
    eyeglasses,
    filled_circle,
    add_noise,
    add_outliers,
    add_dummy_dimensions,
    football_sensor,
    rectangle,
    plot_dataset,
    plot_dataset_3d,
)
from pytesis.results import run_all_intervals, run_all, get_intervals_times_table
from pytesis.utils import compose
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from functools import partial

import random

random.seed(4)

# Multiprocessing stuff
if __name__ == '__main__':
    __spec__ = "multiprocessing-stuff"
```


```{python}
# Common
n = 500
sd = 0.075
iqr_factor = 0.3
outliers_frac = 0.02
h = 0.3
B_intervals = 300
B_power = 50
robust_quantile = 0.97
# Eyeglasses
n_eyeglasses = 750
bridge_height = 0.6
sd_eyeglasses = 0.05
h_eyeglasses = 0.25
# h_eyeglasses = 0.20
# Filled circle
n_filled = 750
r_power = 2.6
max_r = 1.5
h_filled = 0.3

# Circle
circle_factory = partial(arc, n=n)
circle_noise_factory = compose(partial(add_noise, sd=sd), partial(arc, n=n))
circle_outliers_factory = compose(
    partial(add_outliers, frac=outliers_frac, iqr_factor=iqr_factor),
    partial(arc, n=n)
)
X_circle = circle_factory()
X_circle_noise = circle_noise_factory()
X_circle_outliers = circle_outliers_factory()

# Circle Gauss
circle_gauss_factory = partial(arc, n=n, sampling="normal")
circle_gauss_noise_factory = compose(partial(add_noise, sd=sd), circle_gauss_factory)
circle_gauss_outliers_factory = compose(
    partial(add_outliers, frac=outliers_frac, iqr_factor=iqr_factor),
    circle_gauss_factory
)
X_circle_gauss = circle_gauss_factory()
X_circle_gauss_noise = circle_gauss_noise_factory()
X_circle_gauss_outliers = circle_gauss_outliers_factory()

# Eyeglasses
eyeglasses_factory = partial(eyeglasses, n=n_eyeglasses, bridge_height=bridge_height)
eyeglasses_noise_factory = compose(partial(add_noise, sd=sd_eyeglasses), eyeglasses_factory)
eyeglasses_outliers_factory = compose(
    partial(add_outliers, frac=outliers_frac, iqr_factor=iqr_factor),
    eyeglasses_factory
)
X_eyeglasses = eyeglasses_factory()
X_eyeglasses_noise = eyeglasses_noise_factory()
X_eyeglasses_outliers = eyeglasses_outliers_factory()

# Filled
filled_circle_factory = partial(filled_circle, n=n_filled, r_power=r_power, max_r=max_r)
X_filled = filled_circle_factory()
```

## Conjuntos de Datos Sintéticos {#sec-results-synth}

### Diagramas de persistencia y regiones de confianza {#sec-results-diagrams-plus-intervals}

A continuación se presentan, individualmente para cada uno de los conjuntos de datos, los diagramas de persistencia y regiones de confianza computadas sobre los mismos para cada uno de los métodos

#### Circunferencia uniforme {#sec-results-diagrams-plus-intervals-circle}

```{python}
#| label: fig-sim-intervals-circle-base
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para la circunferencia uniforme
intervals_circle_base = run_all_intervals(
    X_circle,
    h=h,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="circle_base"
)
```

```{python}
#| label: fig-sim-intervals-circle-noise
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para la circunferencia uniforme con ruido agregado.
intervals_circle_noise = run_all_intervals(
    X_circle_noise,
    h=h,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="circle_noise"
)
```

```{python}
#| label: fig-sim-intervals-circle-outliers
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para la circunferencia uniforme con muestras atípicas agregadas.
intervals_circle_outliers = run_all_intervals(
    X_circle_outliers,
    h=h,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="circle_outliers"
)
```


En las Figuras [-@fig-sim-intervals-circle-base], [-@fig-sim-intervals-circle-noise] y [-@fig-sim-intervals-circle-outliers] se observan, respectivamente, los resultados obtenidos para el dataset original, ruido agregado y datos atípicos. En cada figura se observa el conjunto de datos muestreado sobre su densidad empírica, junto con los tres diagramas de persistencia obtenidos, correspondientes a cada uno de los métodos desarrollados, sobre los cuales se indica la región de confianza resultante.
Se observa que para este conjunto de datos, todos los métodos logran detectar correctamente la existencia de un agujero, no viéndose este resultado afectado por la presencia de ruido ni de datos atípicos.
Vale la pena destacar que Fermat muestra también una componente de grado 0 para cada uno de los datos atípicos, esto resulta interesante ya que podríamos detectar estos *outliers* mirando el diagrama de persistencia. Esto tiene mucho sentido ya que los outliers se encuentran lejos de la masa de datos, por lo que podrían tranquilamente ser parte de otra componente conexa de la topología. Fermat resulta entonces el único método que logra detectar este comportamiento de forma explícita.

#### Circunferencia Gaussiana {#sec-results-diagrams-plus-intervals-circle-gauss}

```{python}
#| label: fig-sim-intervals-circle-gauss-base
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para la circunferencia gaussiana
intervals_circle_gauss_base = run_all_intervals(
    X_circle_gauss,
    h=h,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="circle_gauss_base"
)
```

```{python}
#| label: fig-sim-intervals-circle-gauss-noise
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para la circunferencia gaussiana con ruido agregado.
intervals_circle_gauss_noise = run_all_intervals(
    X_circle_gauss_noise,
    h=h,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="circle_gauss_noise"
)
```

```{python}
#| label: fig-sim-intervals-circle-gauss-outliers
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para la circunferencia gaussiana con muestras atípicas agregadas.
intervals_circle_gauss_outliers = run_all_intervals(
    X_circle_gauss_outliers,
    h=h,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="circle_gauss_outliers"
)
```


Análogamente a los resultados de obtenidos para el muestreo uniforme sobre la circunferencia (@sec-results-diagrams-plus-intervals-circle), en las Figuras [-@fig-sim-intervals-circle-gauss-base], [-@fig-sim-intervals-circle-gauss-noise] y [-@fig-sim-intervals-circle-gauss-outliers] se observan los resultados para el caso del muestreo gaussiano sobre la circunferencia. Se observa que los resultados son también análogos a los obtenidos en el caso uniforme, ya que en todos los casos se logra detectar de forma apropiada los agujeros de la topología subyacente. Esto demuestra que ninguno de los métodos se ve notoriamente afectado por la diferencia de densidad en el muestreo de las diferentes zonas. KDE podría ser el método más afectado dada las hipótesis con las cuales este método se desarrolla, pero para los hiperparámetros y cantidad de muestras probados el mismo no muestra dificultades para descartar correctamente la hipótesis nula en este caso.
Resulta destacable que, nuevamente, Fermat es el único método que evidencia los datos atípicos como conjuntos conexos por encima de la región de confianza.


#### Anteojos {#sec-results-diagrams-plus-intervals-eyeglasses}

```{python}
#| label: fig-sim-intervals-eyeglasses
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para los anteojos
intervals_eyeglasses = run_all_intervals(
    X_eyeglasses,
    h=h_eyeglasses,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="eyeglasses"
)
```

```{python}
#| label: fig-sim-intervals-eyeglasses-noise
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para los anteojos con ruido agregado
intervals_eyeglasses_noise = run_all_intervals(
    X_eyeglasses_noise,
    h=h_eyeglasses,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="eyeglasses_noise"
)
```

```{python}
#| label: fig-sim-intervals-eyeglasses-outliers
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para los anteojos con datos atípicos agregados
intervals_eyeglasses_outliers = run_all_intervals(
    X_eyeglasses_outliers,
    h=h_eyeglasses,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="eyeglasses_outliers"
)
```

Para el conjunto de datos de anteojo, que se observa en las Figuras [-@fig-sim-intervals-eyeglasses], [-@fig-sim-intervals-eyeglasses-noise] y [-@fig-sim-intervals-eyeglasses-outliers] para las variantes base, con ruido agregado y datos atípicos, respectivamente, se observa que los resultados son altamente favorables para Fermat en todos los casos, siendo el único capaz de detectar un único agujero de primer grado en todos los casos. Puntualmente, para el caso base (@fig-sim-intervals-eyeglasses) se observa que tanto el método euclídeo como KDE detectan muy claramente dos agujeros significativos, esto resulta así para distintos valores probados para el hiperparámetro $h$ en el caso de KDE, que se varió con el objetivo de obtener mejores resultados para este método. Fermat mantiene su correcta interpretación detectando un único agujero significativo con mucha claridad.
Para el conjunto de datos con ruido agregado (@fig-sim-intervals-eyeglasses-noise) se observa una historia análoga, en la que ninguno de los métodos evaluados cambia el resultado obtenido.
El caso de datos atípicos añadidos resulta interesante, ya que se observa en la @fig-sim-intervals-eyeglasses-outliers que el método euclídeo logra detectar un único agujero significativo de primer grado, aunque esto se debe, lamentablemente, no a una mejora atribuible a el método en cuestión, sino a la distribución de datos atípicos, que logra rellenar el agujero derecho del anteojos, de forma tal que el método euclídeo termine solamente detectando como un agujero significativo el izquierdo, que si bien es el resultado esperando nominalmente, se obtiene por las razones equivocadas. Para KDE la historia es análoga a la de los casos anteriores, ya que continúa detectando dos agujeros significativos. Fermat logra nuevamente, no solo detectar un único agujero significativo de primer orden, sino que también logra atribuirle una componente conexa significativa a cada uno de los datos atípicos, como sucedió en cada uno de los conjuntos de datos anteriores cuando se le adicionan esta contaminación. Aunque la detección de *outliers* como componentes conexas no es nuestro foco en este trabajo, es un resultado interesante que merece ser analizado en más detalle.


#### Círculo con densidad dependiente del radio {#sec-results-diagrams-plus-intervals-filled-circle}


```{python}
#| label: fig-sim-intervals-filled-circle
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para el círculo relleno
intervals_filled_circle = run_all_intervals(
    X_filled,
    h=h_filled,
    robust_quantile=robust_quantile,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="filled_circle",
)
```

En la @fig-sim-intervals-filled-circle se observan los resultados obtenidos, según cada uno de los métodos, para el círculo relleno con densidad dependiente del radio. Recordemos que, como fue introducido en la @sec-methods-data-synth-filled-circle, en el mismo se espera que los distintos métodos logren aceptar la hipótesis nula, es decir, que no se detecte un agujero de primer grado en la topología subyacente. Se observa en la @fig-sim-intervals-filled-circle que el método de densidad (KDE) es el único que no logra rechazar la hipótesis nula, mostrando un agujero de grado uno significativo, es decir, por encima de la región de confianza. Este resultado resulta muy relevante ya que nos da a entender que las cualidades de robustez a la hora de calcular los diagramas de persistencia en los casos anteriores, especialmente en presencia de ruido o datos atípicos, pueden estar resultando positivamente a expensas de una distorsión en la topología subyacente que hace que se pierda la significancia a la hora de evaluar topologías sin estos agujeros, perdiéndose la noción de lo que es el nivel de un *test* estadístico.


### Potencia {#sec-results-power}

Si ahora se repite el procedimiento realizado en la @sec-results-diagrams-plus-intervals un cantidad $M = `{python} B_power`$  de veces con el objetivo de analizar la frecuencia en la que la región estimada no contiene efectivamente a la cantidad de agujeros reales, siendo en nuestro caso un agujero real para todos los conjuntos de datos analizados, entonces se obtiene la potencia estimada de la prueba de hipótesis sobre una variedad, es decir, la probabilidad de rechazar la hipótesis nula $H_0$ dado que esta es falsa. Como se detalló en la @sec-homologia-intervalos, se define una hipótesis nula $H^{i}_0$ para cada una de las cualidades topológicas que resultan del diagrama de persistencia, manifestándose estas como un punto $p_i$ con tiempo de vida $l_i = d_i - b_i$ en dicho gráfico. Estas hipótesis se expresan entonces como:

$$
H^{i}_0: l_i = d_i - b_i = 0
$$

Donde las mismas se evalúan en simultáneo con nivel $1 - \alpha$. Como se mencionó en la @sec-homologia-intervalos y en [@ConfidenceSetsForPersistenceDiagrams], esta interpretación de la región de confianza construida sobre el diagrama de persistencia que consiste en caracterizar de forma dicotómica, como "ruido" o "señal", a las cualidad topológicas individuales no es la única interpretación posible. La región de confianza construida da un conjunto $\mathcal{C}_n$ posible de variedades $\mathcal{M}$ de las cuales nuestro conjunto de datos finito de $n$ elementos podría haberse muestreado, esto significa que el nivel de $1 - \alpha$ fijado para la prueba no solo es asintótico, sino que es para la variedad de la cual se obtiene nuestro conjunto de datos, no para la muestra de datos específica. De esta forma, resulta interesante ver cómo distintas muestras de una misma variedad varían en su pertenencia al conjunto $\mathcal{C}_n$ y cómo las distintas técnicas utilizadas para construir el diagrama logran modificar este conjunto de variedades posibles a nivel $1 - \alpha$ para el número de muestras utilizado.

```{python}
base_results_params = dict(
    h=h,
    B_power=B_power,
    B_interval=B_intervals,
    robust_quantile=robust_quantile,
    log=False,
    plot=False,
)
eyeglasses_results_params = base_results_params | dict(h=h_eyeglasses)
filled_results_params = base_results_params | dict(h=h_filled)
```

```{python}
#| label: code-run-all-circle
circle_results = run_all(circle_factory, **base_results_params)
```

```{python}
#| label: code-run-all-circle-noise
circle_noise_results = run_all(circle_noise_factory, **base_results_params)
```

```{python}
#| label: code-run-all-circle-outliers
circle_outliers_results = run_all(circle_outliers_factory, **base_results_params)
```


```{python}
#| label: code-run-all-circle-gauss
circle_gauss_results = run_all(circle_gauss_factory, **base_results_params)
```

```{python}
#| label: code-run-all-circle-gauss-noise
circle_gauss_noise_results = run_all(circle_gauss_noise_factory, **base_results_params)
```

```{python}
#| label: code-run-all-circle-gauss-outliers
circle_gauss_outliers_results = run_all(circle_gauss_outliers_factory, **base_results_params)
```

```{python}
#| label: code-run-all-eyeglasses
eyeglasses_results = run_all(eyeglasses_factory, **eyeglasses_results_params)
```

```{python}
#| label: code-run-all-eyeglasses-noise
eyeglasses_noise_results = run_all(eyeglasses_noise_factory, **eyeglasses_results_params)
```

```{python}
#| label: code-run-all-eyeglasses-outliers
eyeglasses_outliers_results = run_all(eyeglasses_outliers_factory, **eyeglasses_results_params)
```

```{python}
#| label: code-run-all-filled
filled_circle_results = run_all(filled_circle_factory, **filled_results_params)
```

```{python}
from pytesis.results import Results

def get_mega_table(results_methods: list[tuple[Results, str]]) -> pd.DataFrame:
    mega_table = None
    for (result, method) in results_methods:
        table = result.powers.copy()
        table.drop("# Detecciones", axis=1, inplace=True)
        column_tuples = [(method, c) for c in table.columns]
        table.columns = pd.MultiIndex.from_tuples(
            column_tuples, names=["Método", "Resultado"]
        )
        if mega_table is None:
            mega_table = table
        else:
            mega_table = mega_table.join(table, how="outer")
    mega_table.fillna(0, inplace=True)
    return mega_table
```

```{python}
results_methods_base = [
    (circle_results, "Circunferencia uniforme"),
    (circle_gauss_results, "Circunferencia Gaussiana"),
    (eyeglasses_results, "Anteojos"),
]
results_methods_noise = [
    (circle_noise_results, "Circunferencia uniforme"),
    (circle_gauss_noise_results, "Circunferencia Gaussiana"),
    (eyeglasses_noise_results, "Anteojos"),
]
results_methods_outliers = [
    (circle_outliers_results, "Circunferencia uniforme"),
    (circle_gauss_outliers_results, "Circunferencia Gaussiana"),
    (eyeglasses_outliers_results, "Anteojos"),
]
mega_table_base = get_mega_table(results_methods_base)
mega_table_noise = get_mega_table(results_methods_noise)
mega_table_outliers = get_mega_table(results_methods_outliers)
mega_table_filled_circle = get_mega_table([
    (filled_circle_results, "Círculo con densidad dependiente del radio")
])
```

```{python}
from IPython.display import Math, Latex, Markdown, HTML

def get_printable_table(mega_table: pd.DataFrame) -> Markdown:
    new_df = mega_table.reset_index()
    n_columns = len(new_df.columns)
    if n_columns == 5:
        new_df.columns = [
            "Método",
            "Agujeros",
            "Circunferencia Uniforme Porcentaje de Detecciones",
            "Circunferencia Gaussiana Porcentaje de Detecciones",
            "Anteojos Porcentaje de Detecciones"
        ]
    elif n_columns == 3:
        new_df.columns = [
            "Método",
            "Agujeros",
            "Porcentaje de Detecciones"
        ]
    new_df = new_df.to_markdown(index=False)
    return Markdown(new_df)
    # new_df = new_df.to_html(index=False)
    # return HTML(new_df)
```


::: {#tbl-power-table-base}

```{python}
get_printable_table(mega_table_base)
```

Resultados de potencia estimada para los tres métodos sobre los conjuntos de datos originales. Cada fila de la tabla muestra, según el método que se indica a la izquierda, el porcentaje de veces ($\frac{\#}{M} * 100$) que cada cantidad de agujeros fue detectada de forma significativa en las corridas realizadas.

:::

En la @tbl-power-table-base se observan los resultados para los conjuntos de datos base, sin presencia de ruido o datos atípicos agregados. Se observa que el único método que logra detectar, el 100% de las ocasiones que la topología subyacente consiste en un único agujero es Fermat. Si bien tanto el método Euclídeo como KDE logran acertar para los casos de circunferencias de muestreo uniforme y gaussiana, respectivamente, fracasan para el conjunto de datos con forma de anteojos, en el cual ambos métodos logran encontrar siempre dos agujeros significativos. Esto nos comienza a demostrar que las intuiciones construidas sobre los diagramas de persistencia individuales de la @sec-results-diagrams-plus-intervals generalizan para diferentes muestras de las mismas topologías. Esto no resulta asombroso, ya que las topologías sintéticas estudiadas son bastante estables, es decir, por más que cambien los puntos exactos muestreados es fácil reconstruir la misma topología.


::: {#tbl-power-table-noise}

```{python}
get_printable_table(mega_table_noise)
```

Resultados obtenidos para los conjuntos de datos con ruido agregado, análogamente a lo obtenido en la @tbl-power-table-base para los conjuntos base

:::

Se muestran en la @tbl-power-table-noise los resultados para los conjuntos de datos con ruido agregado. La conclusiones resultan altamente similares a las obtenidas en la @tbl-power-table-base para los conjuntos base, con la única salvedad de que, si bien sigue siendo el único método en correctamente detectar a los anteojos como una topología de un único agujero significativo con alta potencia, el método de Fermat detecta en limitadas ocasiones (2%) dos agujeros significativos en los Anteojos. Esto se debe, posiblemente, a que la presencia de ruido en el canal que une a las dos circunferencias principales de los anteojos puede llegar "engañar" al método reduciendo el ancho de este canal. Para los casos de circunferencias ninguno de los tres métodos se ve afectado por la presencia del ruido en la varianza estudiada ($\sigma = `{python} sd`$).


```{python}
#| label: tbl-power-table-outliers
#| tbl-cap: Resultados de potencia estimada obtenidos para los conjuntos de datos con datos atípicos agregados
get_printable_table(mega_table_outliers)
```

En la @tbl-power-table-outliers se observan los resultados para el caso de datos atípicos agregados. Para este ejercicio, se observa un poco más de variabilidad en los resultados obtenidos corrida a corrida. Por ejemplo, para el caso del método Euclídeo, se observa que además de seguir detectando apropiadamente un único agujero para las circunferencias de muestreo uniforme y gaussiano, ahora también logra detectar correctamente, en el 80% de los casos, que los Anteojos presentan un único agujero significativo. Esto se debe seguramente a que los datos atípicos que se encuentran en el espacio de relleno de los dos agujeros principales de la topología logran reducir el área efectiva del agujero, llevándola una proporción similar a la del túnel que los une, por lo que la interpretación de la reconstrucción mediante homología persistente del método Euclídeo es que hay un único agujero de aproximadamente el tamaño del túnel. La aparición de estos datos atípicos también afecta considerablemente al método de Fermat, en el cual aparecen incluso equivocaciones, aunque en un número muy reducido de ocasiones (2%), para la circunferencia de muestreo uniforme. De nuevo, el conjunto de datos más afectados resulta ser el de Anteojos, ya que una cantidad finita de datos atípicos bien ubicados (como puede ser en el medio del túnel), resulta en detecciones espurias de más agujeros significativos.


```{python}
#| label: tbl-power-table-filled
#| tbl-cap: Resultados de potencia estimada obtenidos para el conjunto de datos del círculo relleno con densidad dependiente del radio, en el que el resultado esperado sería la aceptación de la hipótesis nula, es decir, detectar cero agujeros
get_printable_table(mega_table_filled_circle)
```

Resulta importante destacar que los resultados obtenidos para el método de ventanas de densidad (KDE) no varían en ningún caso, como se observa en las tablas [-@tbl-power-table-base], [-@tbl-power-table-noise] y [-@tbl-power-table-outliers]. Un primer instinto podría indicarnos que esto se debe a una propiedad de robustez del método, como se analiza en el trabajo que introduce este algoritmo [@ConfidenceSetsForPersistenceDiagrams], tal que el ruido y los datos atípicos no afectan las buenas propiedades del mismo. Si bien esto tiene mucho sentido, ya que al usar ventanas de densidad la topología sobre la cual se realiza el test es en realidad una versión suavizada de la original, ocultándose las cualidades ruidosas del conjunto y centrándose en las características principales de la topología subyacente, es también posible que en ese proceso se escondan o se pierdan cualidades que eran de interés para reconstruir la topología subyacente verdadera de la variedad $\mathcal{M}$ bajo estudio. Esto puede evidenciarse en la @tbl-power-table-filled, en la que ahora las corridas se realizan sobre diferentes conjuntos de datos obtenidos de una distribución que muestrea sobre un círculo en el que la densidad de probabilidad es dependiente del radio, como se introdujo en la @sec-methods-data-synth-filled-circle. Se observa que tanto el método Euclídeo como el de Fermat detectan correctamente que la topología subyacente no presenta ningún agujero, mientras que el método de ventanas de densidad (KDE) descarta la existencia de agujeros solo el 50% de las veces. La explicación más plausible para este comportamiente es que, debido a la distorsión generada por KDE en la topología original y a la baja densidad cercana al origen de la topología, para el número de muestras analizado la región de confianza $1 - \alpha$ no logra incluir a la variedad que genera este conjunto de datos en el conjunto $\mathcal{C}_n$ de posibles variedades.


## Conjuntos de Datos Sintéticos en Dimensiones Superiores {#sec-results-synth-higher-dim}

Una observación importante es que en ningún momento del trabajo se discutió analizar conjuntos de datos, sintéticos o no, cuya dimensión de origen sea superior a dos, es decir $D > 2$. Esto se debe a que una parte fundamental de la presente Tesis es contrastar el comportamiento del método de Fermat con el de KDE, y este último presenta un grave problema a la hora de ser evaluado en conjuntos de datos provenientes de dimensiones superiores. Esto se debe a que para obtener el diagrama de persistencia mediante KDE, o cualquier otro conjunto de nivel de una función, como se introdujo en la @sec-intro-dgm-function, se requiere trazar una grilla de $M_h$ puntos por dimensión, sobre la cual evaluar la función cuyos conjuntos de nivel son de interés. Teniendo en cuenta que la cantidad de estos puntos condiciona la sensibilidad que se tiene sobre el espacio, resulta importante que $M_h$ sea lo más alto posible, por ejemplo para los casos discutidos en las secciones precedentes, se utilizó $M_h = 100$. Teniendo en cuenta que la cantidad de puntos a evaluar y que serán posteriormente utilizados en la construcción del diagrama de persistencia crecen de forma exponencial con la dimensión del espacio ($k = M_h^D$), y que la complejidad algorítmica de la construcción del diagrama de persistencia escala también de forma exponencial con la cantidad de dimensiones ($\mathcal{O}(k^D) = \mathcal{O}(M_h^{D^2})$) [@CubicalPersistentDiagrams], Para los recursos computacionales trabajados una dimensión $D = 3$ ya se torna computacionalmente muy costosa. Resulta importante destacar que esto no sucede para los métodos que se basan en distancias, ya que para estos la complejidad computacional en la construcción del diagrama de persistencia solo depende de la cantidad de puntos, que no depende entonces de la dimensionalidad del espacio.

A modo de ejemplo, podemos ilustrar esta ventaja de los métodos basados en distancia para un conjunto de datos de mayor dimensionalidad construido de forma sencilla: Tomamos el conjunto de datos de la circunferencia uniforme, introducido en la @sec-methods-data-synth, y agregamos dimensiones con valores constantes a cada muestra. Para un ejemplo de dos puntos, este procedimiento se vería de la siguiente forma: si tenemos dos puntos muestreados de la circunferencia $x_1 = [0, 1]$ y $x_2 = [1, 0]$, obtenemos muestras en mayores dimensiones como $\hat{x}_1 = [0, 1, \sigma_D^{1}, \dots, \sigma_D^{L}]$ y $\hat{x}_2 = [1, 0, \sigma_D^{1}, \dots, \sigma_D^{L}]$. Lo que se obtiene es la misma circunferencia pero embebida en un espacio de dimensión mayor, en donde la muestra se encuentra ahora viviendo en un plano distinto. En la @fig-circle-more-dims se ilustra este procedimiento para $L = 1$, dando lugar a una circunferencia suspendida en un plano del tercer eje de $\mathbb{R}^3$.

```{python}
#| label: fig-circle-more-dims
#| fig-cap: Conjunto de datos correspondientes a la circunferencia uniforme con un agregado de una variable adicional que toma un valor constante para todas las muestras, con el objetivo de suspender el conjunto de datos en un plano diferente de un espacio de dimensionalidad superior
timing_grid_n = 30
X_circle_dims_3 = add_dummy_dimensions(X_circle, d=1)
X_circle_dims_4 = add_dummy_dimensions(X_circle, d=2)

dims_3_ax = plot_dataset(X_circle_dims_3, title="Circunferencia con D = 3")
dims_3_ax.set_facecolor("white")
plt.show()
```

A partir de este nuevo conjunto de datos, podemos realizar el cálculo del diagrama de persistencia y su respectiva región de confianza variando la dimensión $D$ y observando cómo este procedimiento se vuelve más computacionalmente costoso. En la @tbl-timing-dims-results se ilustra este fenómeno, donde se muestra el tiempo demorado, medido en segundos, para cada método en obtener la región de confianza al tomar las dimensiones $D = 2, 3, 4$. Se observa claramente que los métodos Euclídeo y Fermat no varían en el tiempo demorado, pero KDE crece exponencialmente en el mismo. Para realizar estas pruebas se utilizó $M_h = `{python} timing_grid_n`$, siendo este valor menor al que se utilizó en el resto de los experimentos para conjuntos de datos en dimensión dos ($M_h = 100$), esto se debe a que de otra forma el tiempo requerido para el cómputo con $D = 4$ hubiese sido innecesariamente excesivo.

```{python}
intervals_circle_timed = run_all_intervals(
    X_circle,
    h=h_eyeglasses,
    robust_quantile=robust_quantile,
    grid_n=timing_grid_n,
    log=False,
    plot=False,
    B=B_intervals,
    cache_prefix=f"circle_dims_original"
)
intervals_dummy_dims_3 = run_all_intervals(
    X_circle_dims_3,
    h=h,
    robust_quantile=robust_quantile,
    grid_n=timing_grid_n,
    log=False,
    plot=False,
    B=B_intervals,
    cache_prefix=f"circle_dims_3"
)
intervals_dummy_dims_4 = run_all_intervals(
    X_circle_dims_4,
    h=h,
    robust_quantile=robust_quantile,
    grid_n=timing_grid_n,
    log=False,
    plot=False,
    B=B_intervals,
    cache_prefix=f"circle_dims_4"
)

timing_dims_results = get_intervals_times_table(intervals_circle_timed)
timing_dims_results["Dimensiones"] = "2"
timing_dims_results_3 = get_intervals_times_table(intervals_dummy_dims_3)
timing_dims_results_3["Dimensiones"] = "3"
timing_dims_results_4 = get_intervals_times_table(intervals_dummy_dims_4)
timing_dims_results_4["Dimensiones"] = "4"
timing_dims_results = pd.concat(
    [timing_dims_results, timing_dims_results_3, timing_dims_results_4]
)
```

```{python}
#| label: tbl-timing-dims-results
#| tbl-cap: Costo computacional, representado en segundos que se demora en la construcción del diagrama de pesistencia y su correspondiente región de confianza para los distintos métodos estudiados y tres dimensionalidades diferentes. Se observa cómo los métodos basados en distancia (Euclídeo y Fermat) no varían en el tiempo demandando, mientras que KDE escala exponencialmente.
from IPython.display import Markdown, Latex

timing_dims_results = timing_dims_results.reset_index(drop=True).set_index("Dimensiones")
timing_dims_results = timing_dims_results.map("{:.2f}".format)
# Latex(timing_dims_results.style.highlight_max(
#     axis=None,props='cellcolor:{red}; bfseries: ;'
# ).to_latex(convert_css=True, hrules=True))
timing_dims_results
```

## Conjuntos de Datos Reales {#sec-results-real-data}

El trabajar con conjuntos de datos sintéticos nos permite evaluar nuestros resultados a lo largo de diferentes muestras de la misma distribución, como se realizó en la @sec-results-power, pero resulta también muy importante analizar cómo estos métodos se comportan con conjuntos de datos reales, de los cuales interpretaciones relevantes del dominio de aplicación puedan extraerse a partir de las cualidades significativas del diagrama de persistencia para cada uno de los métodos. En línea con el trabajo realizado en [@FootballRobustDataset] utilizaremos el conjunto de datos reales allí utilizado, que como se explicó brevemente en la @sec-methods-data-real, consiste en mediciones correspondientes a la posición de jugadores de fútbol dentro de la cancha a lo largo de un partido, en el que se obtiene un punto cada un intervalo de tiempo determinado. Con el objetivo de obtener agujeros en las zonas donde los jugadores no participan activamente, se agregan artificialmente puntos en los bordes del conjunto de datos, correspondientes a los límites de la cancha [@FootballRobustDatasetExplanation]. Los diferentes jugadores ocupan diferentes espacios en la cancha, en función de la posición que ocupan en el juego, por lo que analizaremos por separado los diferentes jugadores elegidos

```{python}
n_borders = 100
n_football = 1000
h_football = 4
robust_quantile_football = 0.93

length_x, length_y = 105, 68
borders = rectangle(n=n_borders, length_x=length_x, length_y=length_y, random=False)

football_tag_2 = football_sensor(n=n_football, tag_id=2, second_half=False)
football_tag_5 = football_sensor(n=n_football, tag_id=5, second_half=False)
football_tag_8 = football_sensor(n=n_football, tag_id=8, second_half=False)
football_tag_14 = football_sensor(n=n_football, tag_id=14, second_half=False)

football_X_tag_2 = np.vstack([football_tag_2, borders])
football_X_tag_5 = np.vstack([football_tag_5, borders])
football_X_tag_8 = np.vstack([football_tag_8, borders])
football_X_tag_14 = np.vstack([football_tag_14, borders])
```

### Jugador 2 (Defensor Central)


```{python}
#| label: fig-real-intervals-player-2
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para el jugador identificado como el número 2, que corresponde al comportamiento de un defensor central
intervals_football = run_all_intervals(
    football_X_tag_2,
    h=h_football,
    robust_quantile=robust_quantile_football,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="football_player_2"
)
```

El jugador con identificador número dos corresponde según una inspección visual a un defensor central, ya que se observa en el gráfico de dispersión en la @fig-real-intervals-player-2 que el mismo ocupa mayoritariamente posiciones en el centro del sector correspondiente al lado del arco de su equipo, aunque realiza algunas maniobras ofensivas por el centro al arco rival, posiblemente para cabecear ofensivamente en los tiros de esquina. En esta muestra, el método euclídeo detecta un único agujero significativo, seguido por un agujero que por poco no logra ser significativo, mientras que Fermat detecta dos bien marcados. Una interpretación es que en ambos casos esos dos puntos del diagrama de persistencia para ambos métodos corresponde a las partes inferior y superior de la zona ofensiva del campo de juego, aunque solo Fermat determina que ambas son significativas. Por su parte, KDE no logra detectar ninguna componente significativa, a pesar de que se varió ampliamente los hiperparámetros con los que se obtiene este diagrama no se logró que KDE obtuviera ningún resultado relevante.


### Jugador 5 (Mediocampista)

```{python}
#| label: fig-real-intervals-player-5
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para el jugador identificado como el número 5, que corresponde al comportamiento de un mediocampista
intervals_football = run_all_intervals(
    football_X_tag_5,
    h=h_football,
    robust_quantile=robust_quantile_football,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="football_player_5"
)
```

Para el caso del jugador número 5, puede observarse mediante inspección visual de la @fig-real-intervals-player-5 que el comportamiento del jugador corresponde al de un mediocampista. Se observa que el lateral inferior del campo carece de puntos y que también existen zonas de baja densidad en las esquinas superiores derecha e izquierda, aunque esta última presenta una zona desocupada más reducida. Los distintos métodos obtienen distintos resultados: Como ya se mencionó para el caso del jugador número 2, KDE no logra hacer ningún tipo de detección relevante, sin importar cómo se ajusten los hiperparámetros. El método euclídeo detecta dos agujeros significativos, que no resulta obvio a qué agujeros visuales se corresponden, mientras que Fermat detecta cuatro de estos, que muy posiblemente se correspondan con las cuatro esquinas del campo de juego.


### Jugador 8 (Lateral Izquierdo)

```{python}
#| label: fig-real-intervals-player-8
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para el jugador identificado como el número 8, que corresponde al comportamiento de un lateral izquierdo
intervals_football = run_all_intervals(
    football_X_tag_8,
    h=h_football,
    robust_quantile=robust_quantile_football,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="football_player_8"
)
```

El caso del jugador número 8 resulta el más sencillo de todos, ya que en la inspección visual del diagrama de dispersión en la @fig-real-intervals-player-8 se evidencia de forma clara que el jugador solo ocupa, aunque con buena densidad, la esquina superior izquierda, adentrándose hasta no mucho más que la mitad del campo rival. Esto significa que el comportamiento del jugador se corresponde con el de un lateral izquierdo de corte defensivo, y se espera que los distintos algoritmos detecten con facilidad la existencia de un único agujero significativo. Los métodos de Fermat y Euclídeo no presentan problemas en detectar esta topología subyacente, descartando de la región significativa todo salvo un agujero de primer orden. Análogamente a lo obtenido en los jugadores anteriores, KDE no logra resultados satisfactorios.


### Jugador 14 (Mediocampista)

```{python}
#| label: fig-real-intervals-player-14
#| fig-cap: Conjunto de datos y regiones de confianza obtenidas para el jugador identificado como el número 14, que corresponde al comportamiento de un mediocampista
intervals_football = run_all_intervals(
    football_X_tag_14,
    h=h_football,
    robust_quantile=robust_quantile_football,
    log=False,
    plot=True,
    B=B_intervals,
    cache_prefix="football_player_14"
)
```

En la @fig-real-intervals-player-14 se observa el gráfico de dispersión y los resultados obtenidos según cada uno de los métodos para el jugador número 14. Se observa que el comportamiento de juego del mismo se corresponde con el de un mediocampista, y que exhibe un comportamiento muy similar al del jugador número 5. Esta similitud visual en el comportamiento se manifiesta también en los diagramas de persistencia obtenidos, ya que por ejemplo el método de Fermat detecta, al igual que para el jugador 5 y con una composición muy similar, cuatro agujeros significativos que seguramente estén asociados a las cuatro esquinas del campo de juego. El caso del método Euclídeo es similar, ya que el diagrama de persistencia muestra similitud con el obtenido para el jugador 5 en el que cinco puntos se alejan de la diagonal considerablemente, sin embargo, en este caso solo un agujero se detecta como significativo, a diferencia del caso del jugador 5 en el que se detectaron dos
